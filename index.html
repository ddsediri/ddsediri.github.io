<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="7b4Qude5nf2U5PnmAxp16doNxYsehUCA8_8IK3l61iI"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Dasith de Silva Edirimuni</title> <meta name="author" content="Dasith de Silva Edirimuni"> <meta name="description" content="Hi, my name is Dasith and this is the little corner of the internet where you can find information on my journey through academia. "> <meta name="keywords" content="dasith, de silva, edirimuni, machine learning, point cloud, denoising, normal estimation"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.svg"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ddsediri.github.io/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%64%61%73%69%74%68%64%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-4997-5434" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=KACSqS0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/103207090" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/ddsediri" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/dasith-de-silva-edirimuni-295315148" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Dasith de Silva Edirimuni </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <img id="" src="/assets/img/DasithdeSilvaEdirimuni.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="DasithdeSilvaEdirimuni.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> </div> </div> <div class="clearfix"> <p>I was formally trained as a physicist with a Master of Science degree from the University of Melbourne (2017) and a Bachelor of Science in Physics with minors in Mathematics and Computer Science (2013) from Hardin-Simmons University, Abilene, TX. I also completed a Master of Information Technology from Swinburne University, Melbourne in 2020. Most recently, I submitted my PhD thesis, focused on the use of neural encoder-decoder models for point cloud filtering/denoising, to Deakin University, Geelong. Shortly thereafter, I was appointed as a Research Fellow at the University of Western Australia in the group of Prof. Ajmal Mian.</p> <p>My PhD work is on computer vision. More specifically, I work on applications of deep learning to point cloud processing, analysis and generation. I am also interested in the intersection between language and vision.</p> <p><strong>UPDATE:</strong> Currently I am looking to supervise students interested in computer vision problems. Pre-requisites for scholarship applications include outstanding grades in your current Honours or Masters programs. Previous research outputs are also highly valued. Broadly speaking, potential projects will involve applying a variety of modelling approaches for transport problems (such as diffusion, normalizing flows etc.) for 3D generation. Other research avenues include blue-sky research applying 3D representation learning to other physical problems and/or developing new representation learning techniques. Please feel free to reach out to me by email (button at top left corner).</p> </div> <h2><a href="/news/" style="color: inherit;">News</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" class="col-2">Aug 19, 2024</th> <td class="col-12"> Started my appointment at UWA as a Research Fellow focused on 3D computer vision. </td> </tr> <tr> <th scope="row" class="col-2">Jul 1, 2024</th> <td class="col-12"> <strong>SemReg: Semantics Constrained Point Cloud Registration</strong> paper accepted to ECCV 2024! </td> </tr> <tr> <th scope="row" class="col-2">Feb 27, 2024</th> <td class="col-12"> <strong>StraightPCF: Straight Point Cloud Filtering</strong> paper accepted to CVPR 2024! </td> </tr> <tr> <th scope="row" class="col-2">Mar 26, 2023</th> <td class="col-12"> <strong>Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering</strong> paper accepted to the IEEE TVCG journal! </td> </tr> <tr> <th scope="row" class="col-2">Feb 27, 2023</th> <td class="col-12"> <strong>IterativePFN: True Iterative Point Cloud Filtering</strong> paper accepted to CVPR 2023! </td> </tr> <tr> <th scope="row" class="col-2">Mar 9, 2022</th> <td class="col-12"> <strong>Deep Point Cloud Normal Estimation Via Triplet Learning</strong> paper accepted to ICME, 2022! </td> </tr> <tr> <th scope="row" class="col-2">Mar 3, 2021</th> <td class="col-12"> Awarded the University Medal for most outstanding postgraduate student among Swinburne’s 2020 graduating cohort. </td> </tr> <tr> <th scope="row" class="col-2">Dec 14, 2020</th> <td class="col-12"> Graduated from Swinburne University with a Master of Information Technology. </td> </tr> <tr> <th scope="row" class="col-2">Apr 26, 2019</th> <td class="col-12"> <strong>Interaction and structuration of membrane-binding and membrane-excluding colloidal particles in lamellar phases</strong> paper accepted to the Soft Matter journal. </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">Recent publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row" onmouseover="hover('straightpcf', '/assets/img/publication_preview/straightpcf_after.png' );" onmouseout="unhover('straightpcf', '/assets/img/publication_preview/straightpcf_before.png');"> <div class="col-sm-4 preview"> <figure> <picture> <img id="straightpcf" src="/assets/img/publication_preview/straightpcf_before.png" class="preview z-depth-1" width="auto" height="auto" alt="straightpcf_before.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="edirimuni2024straightpcf" class="col-sm-8"> <div class="title"><a href="https://ddsediri.github.io/projects/StraightPCF/">StraightPCF: Straight Point Cloud Filtering</a></div> <div class="author"> <strong>Dasith de Silva Edirimuni</strong>, <a href="https://xuequanlu.com" rel="external nofollow noopener" target="_blank">Xuequan Lu</a>, <a href="https://scholar.google.com.au/citations?user=dqwjm-0AAAAJ" rel="external nofollow noopener" target="_blank">Gang Li</a>, Lei Wei, <a href="https://scholar.google.com.au/citations?user=y5249-IAAAAJ" rel="external nofollow noopener" target="_blank">Antonio Robles-Kelly</a>, and Hongdong Li</div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Point cloud filtering is a fundamental 3D vision task, which aims to remove noise while recovering the underlying clean surfaces. State-of-the-art methods remove noise by moving noisy points along stochastic trajectories to the clean surfaces. These methods often require regularization within the training objective and/or during post-processing, to ensure fidelity. In this paper, we introduce StraightPCF, a new deep learning based method for point cloud filtering. It works by moving noisy points along straight paths, thus reducing discretization errors while ensuring faster convergence to the clean surfaces. We model noisy patches as intermediate states between high noise patch variants and their clean counterparts, and design the VelocityModule to infer a constant flow velocity from the former to the latter. This constant flow leads to straight filtering trajectories. In addition, we introduce a DistanceModule that scales the straight trajectory using an estimated distance scalar to attain convergence near the clean surface. Our network is lightweight and only has ∼530K parameters, being 17% of IterativePFN (a most recent point cloud filtering network). Extensive experiments on both synthetic and real-world data show our method achieves state-of-the-art results. Our method also demonstrates nice distributions of filtered points without the need for regularization. The implementation code can be found at: https://github.com/ddsediri/StraightPCF.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">edirimuni2024straightpcf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{StraightPCF: Straight Point Cloud Filtering}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Silva Edirimuni, Dasith and Lu, Xuequan and Li, Gang and Wei, Lei and Robles-Kelly, Antonio and Li, Hongdong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ddsediri.github.io/projects/StraightPCF/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row" onmouseover="hover('iterativepfn', '/assets/img/publication_preview/iterativepfn_after.png' );" onmouseout="unhover('iterativepfn', '/assets/img/publication_preview/iterativepfn_before.png');"> <div class="col-sm-4 preview"> <figure> <picture> <img id="iterativepfn" src="/assets/img/publication_preview/iterativepfn_before.png" class="preview z-depth-1" width="auto" height="auto" alt="iterativepfn_before.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="edirimuni2023iterativepfn" class="col-sm-8"> <div class="title"><a href="https://ddsediri.github.io/projects/IterativePFN/">IterativePFN: True Iterative Point Cloud Filtering</a></div> <div class="author"> <strong>Dasith de Silva Edirimuni</strong>, <a href="https://xuequanlu.com" rel="external nofollow noopener" target="_blank">Xuequan Lu</a>, <a href="https://zhiwenshao.github.io/" rel="external nofollow noopener" target="_blank">Zhiwen Shao</a>, <a href="https://scholar.google.com.au/citations?user=dqwjm-0AAAAJ" rel="external nofollow noopener" target="_blank">Gang Li</a>, <a href="https://scholar.google.com.au/citations?user=y5249-IAAAAJ" rel="external nofollow noopener" target="_blank">Antonio Robles-Kelly</a>, and <a href="https://personal.ntu.edu.sg/yhe/" rel="external nofollow noopener" target="_blank">Ying He</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The quality of point clouds is often limited by noise introduced during their capture process. Consequently, a fundamental 3D vision task is the removal of noise, known as point cloud filtering or denoising. State-of-the-art learning based methods focus on training neural networks to infer filtered displacements and directly shift noisy points onto the underlying clean surfaces. In high noise conditions, they iterate the filtering process. However, this iterative filtering is only done at test time and is less effective at ensuring points converge quickly onto the clean surfaces. We propose IterativePFN (iterative point cloud filtering network), which consists of multiple IterationModules that model the true iterative filtering process internally, within a single network. We train our IterativePFN network using a novel loss function that utilizes an adaptive ground truth target at each iteration to capture the relationship between intermediate filtering results during training. This ensures that the filtered results converge faster to the clean surfaces. Our method is able to obtain better performance compared to state-of-the-art methods. The source code can be found at https://github.com/ddsediri/IterativePFN.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">edirimuni2023iterativepfn</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{IterativePFN: True Iterative Point Cloud Filtering}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Silva Edirimuni, Dasith and Lu, Xuequan and Shao, Zhiwen and Li, Gang and Robles-Kelly, Antonio and He, Ying}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13530-13539}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPR52729.2023.01300}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ddsediri.github.io/projects/IterativePFN/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row" onmouseover="hover('joint_learning', '/assets/img/publication_preview/joint_learning_after.png' );" onmouseout="unhover('joint_learning', '/assets/img/publication_preview/joint_learning_before.png');"> <div class="col-sm-4 preview"> <figure> <picture> <img id="joint_learning" src="/assets/img/publication_preview/joint_learning_before.png" class="preview z-depth-1" width="auto" height="auto" alt="joint_learning_before.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="edirimuni2022contrastive" class="col-sm-8"> <div class="title"><a href="https://ieeexplore.ieee.org/document/10091230" rel="external nofollow noopener" target="_blank">Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering</a></div> <div class="author"> <strong>Dasith de Silva Edirimuni</strong>, <a href="https://xuequanlu.com" rel="external nofollow noopener" target="_blank">Xuequan Lu</a>, <a href="https://scholar.google.com.au/citations?user=dqwjm-0AAAAJ" rel="external nofollow noopener" target="_blank">Gang Li</a>, and <a href="https://scholar.google.com.au/citations?user=y5249-IAAAAJ" rel="external nofollow noopener" target="_blank">Antonio Robles-Kelly</a> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Point cloud filtering and normal estimation are two fundamental research problems in the 3D field. Existing methods usually perform normal estimation and filtering separately and often show sensitivity to noise and/or inability to preserve sharp geometric features such as corners and edges. In this paper, we propose a novel deep learning method to jointly estimate normals and filter point clouds. We first introduce a 3D patch based contrastive learning framework, with noise corruption as an augmentation, to train a feature encoder capable of generating faithful representations of point cloud patches while remaining robust to noise. These representations are consumed by a simple regression network and supervised by a novel joint loss, simultaneously estimating point normals and displacements that are used to filter the patch centers. Experimental results show that our method well supports the two tasks simultaneously and preserves sharp features and fine details. It generally outperforms state-of-the-art techniques on both tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">edirimuni2022contrastive</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Silva Edirimuni, Dasith and Lu, Xuequan and Li, Gang and Robles-Kelly, Antonio}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Visualization and Computer Graphics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4527-4541}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TVCG.2023.3263866}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10091230}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row" onmouseover="hover('triplet_normal', '/assets/img/publication_preview/triplet_normal_after.png' );" onmouseout="unhover('triplet_normal', '/assets/img/publication_preview/triplet_normal_before.png');"> <div class="col-sm-4 preview"> <figure> <picture> <img id="triplet_normal" src="/assets/img/publication_preview/triplet_normal_before.png" class="preview z-depth-1" width="auto" height="auto" alt="triplet_normal_before.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2022triplet" class="col-sm-8"> <div class="title"><a href="https://doi.org/10.1109/ICME52920.2022.9859844" rel="external nofollow noopener" target="_blank">Deep Point Cloud Normal Estimation Via Triplet Learning</a></div> <div class="author"> Weijia Wang, <a href="https://xuequanlu.com" rel="external nofollow noopener" target="_blank">Xuequan Lu</a>, <strong>Dasith de Silva Edirimuni</strong>, <a href="https://scholar.google.com/citations?hl=en&amp;user=HMEuyCAAAAAJ" rel="external nofollow noopener" target="_blank">Xiao Liu</a>, and <a href="https://scholar.google.com.au/citations?user=y5249-IAAAAJ" rel="external nofollow noopener" target="_blank">Antonio Robles-Kelly</a> </div> <div class="periodical"> <em>In 2022 IEEE International Conference on Multimedia and Expo (ICME)</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Current normal estimation methods for 3D point clouds often show limited accuracy in predicting normals at sharp features (e.g., edges and corners) and less robustness to noise. In this paper, we propose a novel normal estimation method for point clouds which consists of two phases: (a) feature encoding to learn representations of local patches, and (b) normal estimation that takes the learned representation as input and regresses the normal vector. We are motivated that local patches on isotropic and anisotropic surfaces respectively have similar and distinct normals, and these separable features or representations can be learned to facilitate normal estimation. To realise this, we design a triplet learning network for feature encoding and a normal estimation network to regress normals. Despite having a smaller network size compared with most other methods, experiments show that our method preserves sharp features and achieves better normal estimation results especially on computer-aided design (CAD) shapes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2022triplet</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Weijia and Lu, Xuequan and de Silva Edirimuni, Dasith and Liu, Xiao and Robles-Kelly, Antonio}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 IEEE International Conference on Multimedia and Expo (ICME)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Point Cloud Normal Estimation Via Triplet Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICME52920.2022.9859844}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICME52920.2022.9859844}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row" onmouseover="hover('lamellar', '/assets/img/publication_preview/lamellar_after.png' );" onmouseout="unhover('lamellar', '/assets/img/publication_preview/lamellar_before.png');"> <div class="col-sm-4 preview"> <figure> <picture> <img id="lamellar" src="/assets/img/publication_preview/lamellar_before.png" class="preview z-depth-1" width="auto" height="auto" alt="lamellar_before.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zakine2019lamellar" class="col-sm-8"> <div class="title"><a href="http://dx.doi.org/10.1039/C9SM00230H" rel="external nofollow noopener" target="_blank">Interaction and structuration of membrane-binding and membrane-excluding colloidal particles in lamellar phases</a></div> <div class="author"> <a href="https://rzakine.github.io/" rel="external nofollow noopener" target="_blank">Ruben Zakine</a>, <strong>Dasith de Silva Edirimuni</strong>, <a href="https://scholar.google.fr/citations?hl=en&amp;user=FMb_lD0AAAAJ" rel="external nofollow noopener" target="_blank">Doru Constantin</a>, Paolo Galatola, and <a href="http://www.msc.univ-paris-diderot.fr/~jbfournier" rel="external nofollow noopener" target="_blank">Jean-Baptiste Fournier</a> </div> <div class="periodical"> <em>Soft Matter</em>, Jun 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Within the framework of a discrete Gaussian model, we present analytical results for the interaction induced by a lamellar phase between small embedded colloidal particles. We consider the two limits of particles strongly adherent to the adjacent membranes and of particles impenetrable to the membranes. Our approach takes into account the finite size of the colloidal particles, the discrete nature of the layers, and includes the Casimir-like effect of fluctuations, which is very important for dilute phases. Monte Carlo simulations of the statistical behavior of the membrane-interacting colloidal particles account semi-quantitatively, without any adjustable parameters, for the experimental data measured on silica nanospheres inserted within lyotropic smectics. We predict the existence of finite-size and densely packed particle aggregates originating from the competition between attractive interactions between colloidal particles in the same layer and repulsion between colloidal particles one layer apart.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zakine2019lamellar</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zakine, Ruben and de Silva Edirimuni, Dasith and Constantin, Doru and Galatola, Paolo and Fournier, Jean-Baptiste}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interaction and structuration of membrane-binding and membrane-excluding colloidal particles in lamellar phases}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Soft Matter}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4351-4362}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Royal Society of Chemistry}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1039/C9SM00230H}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dx.doi.org/10.1039/C9SM00230H}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Dasith de Silva Edirimuni. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script defer src="/assets/js/figure.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>